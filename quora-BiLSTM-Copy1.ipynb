{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMPORTS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import torch\n",
    "from torchtext import data\n",
    "import spacy\n",
    "from tqdm import tqdm, tqdm_notebook, tnrange\n",
    "tqdm.pandas(desc='Progress')\n",
    "from collections import Counter\n",
    "from textblob import TextBlob\n",
    "from nltk import word_tokenize\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "from torch.autograd import Variable\n",
    "from torchtext.data import Example\n",
    "from sklearn.metrics import f1_score\n",
    "import torchtext\n",
    "\n",
    "\n",
    "SEED = 1234\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "# load spacy tokenizer\n",
    "nlp = spacy.load('en',disable=['parser', 'tagger', 'ner'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOAD PROCESSED TRAINING DATA FROM DISK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"../input/train.csv\")\n",
    "df_test = pd.read_csv(\"../input/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# insincere questions: 1,225,312(93.81%) and # sincere questions: 80,810(6.19%)\n",
      "# Test samples: 56,370(0.043% of train samples)\n"
     ]
    }
   ],
   "source": [
    "sin = len(df_train[df_train[\"target\"]==0])\n",
    "insin = len(df_train[df_train[\"target\"]==1])\n",
    "persin = (sin/(sin+insin))*100\n",
    "perinsin = (insin/(sin+insin))*100            \n",
    "print(\"# insincere questions: {:,}({:.2f}%) and # sincere questions: {:,}({:.2f}%)\".format(sin,persin,insin,perinsin))\n",
    "# print(\"Sinsere:{}% Insincere: {}%\".format(round(persin,2),round(perinsin,2)))\n",
    "print(\"# Test samples: {:,}({:.3f}% of train samples)\".format(len(df_test),len(df_test)/len(df_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"question_text\"] = df_train[\"question_text\"].str.lower()\n",
    "df_test[\"question_text\"] = df_test[\"question_text\"].str.lower()\n",
    "\n",
    "puncts = [',', '.', '\"', ':', ')', '(', '-', '!', '?', '|', ';', \"'\", '$', '&', '/', '[', ']', '>', '%', '=', '#', '*', '+', '\\\\', '•',  '~', '@', '£', \n",
    " '·', '_', '{', '}', '©', '^', '®', '`',  '<', '→', '°', '€', '™', '›',  '♥', '←', '×', '§', '″', '′', 'Â', '█', '½', 'à', '…', \n",
    " '“', '★', '”', '–', '●', 'â', '►', '−', '¢', '²', '¬', '░', '¶', '↑', '±', '¿', '▾', '═', '¦', '║', '―', '¥', '▓', '—', '‹', '─', \n",
    " '▒', '：', '¼', '⊕', '▼', '▪', '†', '■', '’', '▀', '¨', '▄', '♫', '☆', 'é', '¯', '♦', '¤', '▲', 'è', '¸', '¾', 'Ã', '⋅', '‘', '∞', \n",
    " '∙', '）', '↓', '、', '│', '（', '»', '，', '♪', '╩', '╚', '³', '・', '╦', '╣', '╔', '╗', '▬', '❤', 'ï', 'Ø', '¹', '≤', '‡', '√', ]\n",
    "\n",
    "morepuncts = \"\".join(puncts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100%|██████████| 1306122/1306122 [00:05<00:00, 239952.17it/s]\n",
      "Progress: 100%|██████████| 56370/56370 [00:00<00:00, 719036.66it/s]\n",
      "Progress: 100%|██████████| 1306122/1306122 [00:34<00:00, 37987.77it/s]\n",
      "Progress: 100%|██████████| 56370/56370 [00:01<00:00, 38068.51it/s]\n",
      "Progress: 100%|██████████| 1306122/1306122 [00:14<00:00, 88115.56it/s]\n",
      "Progress: 100%|██████████| 56370/56370 [00:00<00:00, 86844.01it/s]\n",
      "Progress: 100%|██████████| 1306122/1306122 [00:04<00:00, 318231.99it/s]\n",
      "Progress: 100%|██████████| 56370/56370 [00:00<00:00, 306066.39it/s]\n"
     ]
    }
   ],
   "source": [
    "def clean_text(x):\n",
    "\n",
    "    x = str(x)\n",
    "    for punct in \"/-'\":\n",
    "        x = x.replace(punct, ' ')\n",
    "    for punct in morepuncts:\n",
    "        x = x.replace(punct, f' {punct} ')\n",
    "    for punct in '?!.,\"#$%\\'()*+-/:;<=>@[\\\\]^_`{|}~' + '“”’':\n",
    "        x = x.replace(punct, '')\n",
    "    return x\n",
    "\n",
    "def clean_numbers(x):\n",
    "\n",
    "    x = re.sub('[0-9]{5,}', '#####', x)\n",
    "    x = re.sub('[0-9]{4}', '####', x)\n",
    "    x = re.sub('[0-9]{3}', '###', x)\n",
    "    x = re.sub('[0-9]{2}', '##', x)\n",
    "    return x\n",
    "\n",
    "def _get_mispell(mispell_dict):\n",
    "    mispell_re = re.compile('(%s)' % '|'.join(mispell_dict.keys()))\n",
    "    return mispell_dict, mispell_re\n",
    "\n",
    "\n",
    "mispell_dict = {'colour':'color',\n",
    "                'centre':'center',\n",
    "                'didnt':'did not',\n",
    "                'doesnt':'does not',\n",
    "                'isnt':'is not',\n",
    "                'shouldnt':'should not',\n",
    "                'favourite':'favorite',\n",
    "                'travelling':'traveling',\n",
    "                'counselling':'counseling',\n",
    "                'theatre':'theater',\n",
    "                'cancelled':'canceled',\n",
    "                'labour':'labor',\n",
    "                'organisation':'organization',\n",
    "                'wwii':'world war 2',\n",
    "                'citicise':'criticize',\n",
    "                'instagram': 'social medium',\n",
    "                'whatsapp': 'social medium',\n",
    "                'snapchat': 'social medium'\n",
    "\n",
    "                }\n",
    "mispellings, mispellings_re = _get_mispell(mispell_dict)\n",
    "\n",
    "def replace_typical_misspell(text):\n",
    "    def replace(match):\n",
    "        return mispellings[match.group(0)]\n",
    "\n",
    "    return mispellings_re.sub(replace, text)\n",
    "\n",
    "\n",
    "df_train[\"question_text\"] = df_train[\"question_text\"].fillna(\"_na_\").values\n",
    "df_test[\"question_text\"] = df_test[\"question_text\"].fillna(\"_na_\").values\n",
    "\n",
    "df_train[\"question_text\"] = df_train[\"question_text\"].progress_apply(lambda x: x.split())\n",
    "df_test[\"question_text\"] = df_test[\"question_text\"].progress_apply(lambda x: x.split())\n",
    "\n",
    "df_train[\"question_text\"] = df_train[\"question_text\"].progress_apply(lambda x: clean_text(x))\n",
    "df_test[\"question_text\"] = df_test[\"question_text\"].progress_apply(lambda x: clean_text(x))\n",
    "\n",
    "df_train[\"question_text\"] = df_train[\"question_text\"].progress_apply(lambda x: clean_numbers(x))\n",
    "df_test[\"question_text\"] = df_test[\"question_text\"].progress_apply(lambda x: clean_numbers(x))\n",
    "\n",
    "df_train[\"question_text\"] = df_train[\"question_text\"].progress_apply(lambda x: replace_typical_misspell(x))\n",
    "df_test[\"question_text\"] = df_test[\"question_text\"].progress_apply(lambda x: replace_typical_misspell(x))\n",
    "\n",
    "df_train.to_csv(\"train2.csv\")\n",
    "df_test.to_csv(\"test2.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a pytorch dataset from the train samples and build a vocabulary using embedding vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load dataframe to csv\n",
    "\n",
    "TEXT = data.Field(lower=True, batch_first=True,tokenize='spacy')#preprocessing=generate_bigrams)\n",
    "LABEL = data.LabelField(dtype=torch.float)\n",
    "qid = data.Field()\n",
    "\n",
    "train_dataset = data.TabularDataset(path='train2.csv', format='csv',\n",
    "                                      fields={'question_text': ('text',TEXT),\n",
    "                                              'target': ('label',LABEL)})\n",
    "final_test_dataset = data.TabularDataset(path='test2.csv', format='csv',\n",
    "                                     fields={'qid': ('qid', qid),\n",
    "                                             'question_text': ('text', TEXT)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT.build_vocab(train_dataset, final_test_dataset, min_freq=3)\n",
    "qid.build_vocab(final_test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchtext\n",
    "vec = torchtext.vocab.Vectors('../input/embeddings/glove.840B.300d/glove.840B.300d.txt', cache='./cache/')\n",
    "# vec = torchtext.vocab.Vectors('wiki-news-300d-1M/wiki-news-300d-1M.vec', cache='./cache/')\n",
    "TEXT.vocab.load_vectors(vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEXT.build_vocab(train_dataset, max_size=50000, vectors=vec)\n",
    "LABEL.build_vocab(train_dataset)\n",
    "TEXT.vocab.vectors.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SPLIT DATA TO TRAINiNG AND VALIDATION SETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, test_dataset = train_dataset.split(split_ratio=0.9,random_state=random.seed(SEED))\n",
    "train_dataset, valid_dataset = train_dataset.split(split_ratio=0.9,random_state=random.seed(SEED))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 512\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "train_iterator = data.BucketIterator(\n",
    "    train_dataset, \n",
    "    batch_size=BATCH_SIZE,sort_key=lambda x: len(x.text),shuffle=True,sort=False, \n",
    "    device=device)\n",
    "test_iterator = data.BucketIterator(\n",
    "    test_dataset, \n",
    "    batch_size=BATCH_SIZE,sort_key=lambda x: len(x.text),train=False,sort=False,\n",
    "    device=device)\n",
    "valid_iterator = data.BucketIterator(\n",
    "    valid_dataset, \n",
    "    batch_size=BATCH_SIZE,sort_key=lambda x: len(x.text),train=False,sort=False, \n",
    "    device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from https://discuss.pytorch.org/t/self-attention-on-words-and-masking/5671/4\n",
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, hidden_size, batch_first=False):\n",
    "        super(SelfAttention, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.batch_first = batch_first\n",
    "\n",
    "        self.att_weights = nn.Parameter(torch.Tensor(1, hidden_size), requires_grad=True)\n",
    "\n",
    "        stdv = 1.0 / math.sqrt(self.hidden_size)\n",
    "        for weight in self.att_weights:\n",
    "            nn.init.uniform_(weight, -stdv, stdv)\n",
    "\n",
    "    def get_mask(self):\n",
    "        pass\n",
    "\n",
    "    def forward(self, inputs, lengths):\n",
    "        if self.batch_first:\n",
    "            batch_size, max_len = inputs.size()[:2]\n",
    "        else:\n",
    "            max_len, batch_size = inputs.size()[:2]\n",
    "            \n",
    "        # apply attention layer\n",
    "        weights = torch.bmm(inputs,\n",
    "                            self.att_weights  # (1, hidden_size)\n",
    "                            .permute(1, 0)  # (hidden_size, 1)\n",
    "                            .unsqueeze(0)  # (1, hidden_size, 1)\n",
    "                            .repeat(batch_size, 1, 1) # (batch_size, hidden_size, 1)\n",
    "                            )\n",
    "    \n",
    "        attentions = torch.softmax(F.relu(weights.squeeze()), dim=-1)\n",
    "\n",
    "        # create mask based on the sentence lengths\n",
    "        mask = torch.ones(attentions.size(), requires_grad=True).cuda()\n",
    "        for i, l in enumerate(lengths):  # skip the first sentence\n",
    "            if l < max_len:\n",
    "                mask[i, l:] = 0\n",
    "\n",
    "        # apply mask and renormalize attention scores (weights)\n",
    "        masked = attentions * mask\n",
    "        _sums = masked.sum(-1).unsqueeze(-1)  # sums per row\n",
    "        \n",
    "        attentions = masked.div(_sums)\n",
    "\n",
    "        # apply attention weights\n",
    "        weighted = torch.mul(inputs, attentions.unsqueeze(-1).expand_as(inputs))\n",
    "\n",
    "        # get the final fixed vector representations of the sentences\n",
    "        representations = weighted.sum(1).squeeze()\n",
    "\n",
    "        return representations, attentions\n",
    "\n",
    "class BaselineLSTM(nn.Module):\n",
    "    def __init__(self, embedding):\n",
    "        super(BaselineLSTM, self).__init__()\n",
    "                \n",
    "        self.embedding = nn.Embedding.from_pretrained(embedding)\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_size=300, hidden_size=128, num_layers=2, batch_first=True, bidirectional=True)\n",
    "        \n",
    "        self.attention = SelfAttention(128*2, batch_first=True)\n",
    "        \n",
    "        self.fc = nn.Linear(128*2, 1)\n",
    "        self.logit = nn.Linear(1, 1)\n",
    "\n",
    "    def forward(self,x, x_len):\n",
    "        x = self.embedding(x)\n",
    "        x = nn.utils.rnn.pack_padded_sequence(x, x_len, batch_first=True)\n",
    "\n",
    "        out, (hidden, _) = self.lstm(x)\n",
    "        \n",
    "        x, lengths = nn.utils.rnn.pad_packed_sequence(out, batch_first=True)\n",
    "        \n",
    "        x, _ = self.attention(x, lengths) \n",
    "        \n",
    "        x = self.fc(x)\n",
    "        x = self.logit(x).view(-1)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = len(TEXT.vocab)\n",
    "EMBEDDING_DIM = 300\n",
    "N_FILTERS = 100\n",
    "OUTPUT_DIM = 1\n",
    "DROPOUT = 0.5\n",
    "\n",
    "# model = CNN(INPUT_DIM, EMBEDDING_DIM, N_FILTERS, FILTER_SIZES, OUTPUT_DIM, DROPOUT)\n",
    "model = BaselineLSTM(pretrained_embedding).to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=10, verbose=True)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "get_n_params(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_embeddings = TEXT.vocab.vectors\n",
    "\n",
    "model.embedding.weight.data.copy_(pretrained_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# optimizer = optim.Adam(model.parameters())\n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()),\n",
    "                    lr=1e-3)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)\n",
    "\n",
    "def binary_accuracy(preds, y, th = 0.5):\n",
    "    \"\"\"\n",
    "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
    "    \"\"\"\n",
    "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
    "    correct = (rounded_preds == y).float() #convert into float for division \n",
    "    acc = correct.sum()/len(correct)\n",
    "    return acc\n",
    "\n",
    "def f1_score_model(preds, y,th = 0.5):\n",
    "    \"\"\"\n",
    "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
    "    \"\"\"\n",
    "    rounded = torch.sigmoid(preds).cpu().apply_(lambda x: 1 if x>=th else 0)\n",
    "    rounded_preds = rounded\n",
    "\n",
    "    return f1_score(y.cpu().numpy(),rounded_preds.cpu().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion,e):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    step = 0\n",
    "    max_loss = 1e5\n",
    "    no_improve_epoch = 0\n",
    "    no_improve_in_previous_epoch = False\n",
    "    fine_tuning = False\n",
    "    train_record = []\n",
    "    val_record = []\n",
    "    losses = []\n",
    "\n",
    "    model.train()\n",
    "    \n",
    "    for batch in iterator:\n",
    "        step += 1\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(batch.text).squeeze(1)       \n",
    "\n",
    "        loss = criterion(predictions, batch.label)\n",
    "        \n",
    "        acc = binary_accuracy(predictions, batch.label)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        if step % 500 == 0:\n",
    "            model.eval()\n",
    "            model.zero_grad()\n",
    "            val_loss = []\n",
    "            for val_batch in iter(valid_iterator):\n",
    "                val_x = val_batch.text.cuda()\n",
    "                val_y = val_batch.label.type(torch.Tensor).cuda()\n",
    "                val_pred = model.forward(val_x).view(-1)\n",
    "                val_loss.append(criterion(val_pred, val_y).cpu().data.numpy())\n",
    "            val_record.append({'step': step, 'loss': np.mean(val_loss)})\n",
    "            print('epcoh {:02} - step {:06} - train_loss {:.4f} - val_loss {:.4f} '.format(\n",
    "                        e, step, np.mean(losses), val_record[-1]['loss']))\n",
    "            if e >= 2:\n",
    "                if val_record[-1]['loss'] <= max_loss:\n",
    "                    save(m=model, info={'step': step, 'epoch': e, 'train_loss': np.mean(losses),\n",
    "                                        'val_loss': val_record[-1]['loss']})\n",
    "                    max_loss = val_record[-1]['loss']\n",
    "                    no_improve_in_previous_epoch = False\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
    "\n",
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for batch in iterator:\n",
    "\n",
    "            predictions = model(batch.text).squeeze(1)\n",
    "            \n",
    "            loss = criterion(predictions, batch.label)\n",
    "\n",
    "            acc = binary_accuracy(predictions, batch.label)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
    "\n",
    "def evaluate_f1(model, iterator, criterion,th=0.5):\n",
    "    \n",
    "    f1_scores = []\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for batch in iterator:\n",
    "\n",
    "            predictions = model(batch.text).squeeze(1)\n",
    "            \n",
    "            f1 = f1_score_model(predictions, batch.label,th=th)\n",
    "            f1_scores.append(f1)\n",
    "        \n",
    "    return np.array(f1_scores).mean()\n",
    "\n",
    "\n",
    "def save(m, info):\n",
    "    torch.save(info, 'best_model.info')\n",
    "    torch.save(m, 'best_model.m')\n",
    "    \n",
    "def load():\n",
    "    m = torch.load('best_model.m')\n",
    "    info = torch.load('best_model.info')\n",
    "    return m, info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EPOCHS = 4\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion,e=epoch)\n",
    "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
    "    \n",
    "    print(f'| Epoch: {epoch+1:02} | Train Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}% | Val. Loss: {valid_loss:.3f} | Val. Acc: {valid_acc*100:.2f}% |')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, m_info = load()\n",
    "m_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = evaluate(model, test_iterator, criterion)\n",
    "\n",
    "print(f'| Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}% |')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = evaluate_f1(model, test_iterator, criterion)\n",
    "print(f'| f1 score: {score:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "val_pred = []\n",
    "val_true = []\n",
    "test_iterator.init_epoch()\n",
    "for val_batch in iter(test_iterator):\n",
    "    val_x = val_batch.text.cuda()\n",
    "    val_true += val_batch.label.cpu().data.numpy().tolist()\n",
    "    val_pred += torch.sigmoid(model.forward(val_x).view(-1)).cpu().data.numpy().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = [0,0,0] # idx, cur, max\n",
    "delta = 0\n",
    "for tmp[0] in np.arange(0.1, 0.501, 0.01):\n",
    "    tmp[1] = f1_score(val_true, np.array(val_pred)>tmp[0])\n",
    "    if tmp[1] > tmp[2]:\n",
    "        delta = tmp[0]\n",
    "        tmp[2] = tmp[1]\n",
    "print('best threshold is {:.4f} with F1 score: {:.4f}'.format(delta, tmp[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "model.zero_grad()\n",
    "test_pred = []\n",
    "test_id = []\n",
    "\n",
    "final_test_iterator = torchtext.data.BucketIterator(dataset=final_test_dataset,\n",
    "                                    batch_size=BATCH_SIZE,\n",
    "                                    sort_key=lambda x: x.text.__len__(),train=False,sort=False)\n",
    "\n",
    "\n",
    "for test_batch in iter(final_test_iterator):\n",
    "    test_x = test_batch.text.cuda()\n",
    "    test_pred += torch.sigmoid(model.forward(test_x).view(-1)).cpu().data.numpy().tolist()\n",
    "    test_id += test_batch.qid.view(-1).data.numpy().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
