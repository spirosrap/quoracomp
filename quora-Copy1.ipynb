{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMPORTS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import torch\n",
    "from torchtext import data\n",
    "import spacy\n",
    "from tqdm import tqdm, tqdm_notebook, tnrange\n",
    "tqdm.pandas(desc='Progress')\n",
    "from collections import Counter\n",
    "import torchnlp\n",
    "from textblob import TextBlob\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "from torch.autograd import Variable\n",
    "from torchtext.data import Example\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "def generate_bigrams(x):\n",
    "    n_grams = set(zip(*[x[i:] for i in range(2)]))\n",
    "    for n_gram in n_grams:\n",
    "        x.append(' '.join(n_gram))\n",
    "    return x\n",
    "\n",
    "\n",
    "SEED = 1234\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "# load spacy tokenizer\n",
    "nlp = spacy.load('en',disable=['parser', 'tagger', 'ner'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOAD PROCESSED TRAINING DATA FROM DISK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to reload the Data frame\n",
    "# df = pd.read_pickle('lastDFTWOCOLUMNS.pkl') #to load back to the dataframe df\n",
    "# df.head()\n",
    "\n",
    "# Uncomment to save to pickle\n",
    "# new.to_pickle('lastDFTWOCOLUMNS.pkl')\n",
    "df_train = pd.read_csv(\"train.csv\")\n",
    "df_test = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(x):\n",
    "\n",
    "    x = str(x)\n",
    "    for punct in \"/-'\":\n",
    "        x = x.replace(punct, ' ')\n",
    "    for punct in '&':\n",
    "        x = x.replace(punct, f' {punct} ')\n",
    "    for punct in '?!.,\"#$%\\'()*+-/:;<=>@[\\\\]^_`{|}~' + '“”’':\n",
    "        x = x.replace(punct, '')\n",
    "    return x\n",
    "\n",
    "def clean_numbers(x):\n",
    "\n",
    "    x = re.sub('[0-9]{5,}', '#####', x)\n",
    "    x = re.sub('[0-9]{4}', '####', x)\n",
    "    x = re.sub('[0-9]{3}', '###', x)\n",
    "    x = re.sub('[0-9]{2}', '##', x)\n",
    "    return x\n",
    "\n",
    "def _get_mispell(mispell_dict):\n",
    "    mispell_re = re.compile('(%s)' % '|'.join(mispell_dict.keys()))\n",
    "    return mispell_dict, mispell_re\n",
    "\n",
    "\n",
    "mispell_dict = {'colour':'color',\n",
    "                'centre':'center',\n",
    "                'didnt':'did not',\n",
    "                'doesnt':'does not',\n",
    "                'isnt':'is not',\n",
    "                'shouldnt':'should not',\n",
    "                'favourite':'favorite',\n",
    "                'travelling':'traveling',\n",
    "                'counselling':'counseling',\n",
    "                'theatre':'theater',\n",
    "                'cancelled':'canceled',\n",
    "                'labour':'labor',\n",
    "                'organisation':'organization',\n",
    "                'wwii':'world war 2',\n",
    "                'citicise':'criticize',\n",
    "                'instagram': 'social medium',\n",
    "                'whatsapp': 'social medium',\n",
    "                'snapchat': 'social medium'\n",
    "\n",
    "                }\n",
    "mispellings, mispellings_re = _get_mispell(mispell_dict)\n",
    "\n",
    "def replace_typical_misspell(text):\n",
    "    def replace(match):\n",
    "        return mispellings[match.group(0)]\n",
    "\n",
    "    return mispellings_re.sub(replace, text)\n",
    "\n",
    "\n",
    "df_train[\"question_text\"] = df_train[\"question_text\"].fillna(\"_na_\").values\n",
    "df_test[\"question_text\"] = df_test[\"question_text\"].fillna(\"_na_\").values\n",
    "\n",
    "# df_train[\"question_text\"] = df_train[\"question_text\"].progress_apply(lambda x: x.split())\n",
    "# df_test[\"question_text\"] = df_test[\"question_text\"].progress_apply(lambda x: x.split())\n",
    "\n",
    "# df_train[\"question_text\"] = df_train[\"question_text\"].progress_apply(lambda x: clean_text(x))\n",
    "# df_test[\"question_text\"] = df_test[\"question_text\"].progress_apply(lambda x: clean_text(x))\n",
    "\n",
    "# df_train[\"question_text\"] = df_train[\"question_text\"].progress_apply(lambda x: clean_numbers(x))\n",
    "# df_test[\"question_text\"] = df_test[\"question_text\"].progress_apply(lambda x: clean_numbers(x))\n",
    "\n",
    "# df_train[\"question_text\"] = df_train[\"question_text\"].progress_apply(lambda x: replace_typical_misspell(x))\n",
    "# df_test[\"question_text\"] = df_test[\"question_text\"].progress_apply(lambda x: replace_typical_misspell(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# insincere questions: 1,225,312(93.81%) and # sincere questions: 80,810(6.19%)\n",
      "# Test samples: 56,370(0.043% of train samples)\n"
     ]
    }
   ],
   "source": [
    "sin = len(df_train[df_train[\"target\"]==0])\n",
    "insin = len(df_train[df_train[\"target\"]==1])\n",
    "persin = (sin/(sin+insin))*100\n",
    "perinsin = (insin/(sin+insin))*100            \n",
    "print(\"# insincere questions: {:,}({:.2f}%) and # sincere questions: {:,}({:.2f}%)\".format(sin,persin,insin,perinsin))\n",
    "# print(\"Sinsere:{}% Insincere: {}%\".format(round(persin,2),round(perinsin,2)))\n",
    "print(\"# Test samples: {:,}({:.3f}% of train samples)\".format(len(df_test),len(df_test)/len(df_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rename columns and remove id column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How did Quebec nationalists see their province...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Do you have an adopted dog, how would you enco...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Why does velocity affect time? Does velocity a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How did Otto von Guericke used the Magdeburg h...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Can I convert montra helicon D to a mountain b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  How did Quebec nationalists see their province...      0\n",
       "1  Do you have an adopted dog, how would you enco...      0\n",
       "2  Why does velocity affect time? Does velocity a...      0\n",
       "3  How did Otto von Guericke used the Magdeburg h...      0\n",
       "4  Can I convert montra helicon D to a mountain b...      0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = df_train[[\"question_text\",\"target\"]]\n",
    "df_train[\"text\"] = df_train[\"question_text\"]\n",
    "df_train[\"label\"] = df_train[\"target\"]\n",
    "df_train = df_train.drop([\"question_text\",\"target\"],axis=1)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>My voice range is A2-C5. My chest voice goes u...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How much does a tutor earn in Bangalore?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What are the best made pocket knives under $20...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Why would they add a hypothetical scenario tha...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What is the dresscode for Techmahindra freshers?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  My voice range is A2-C5. My chest voice goes u...      0\n",
       "1           How much does a tutor earn in Bangalore?      0\n",
       "2  What are the best made pocket knives under $20...      0\n",
       "3  Why would they add a hypothetical scenario tha...      0\n",
       "4   What is the dresscode for Techmahindra freshers?      0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = df_test[[\"question_text\"]]\n",
    "df_test[\"text\"] = df_test[\"question_text\"]\n",
    "df_test[\"label\"] = 0\n",
    "df_test = df_test.drop([\"question_text\"],axis=1)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ince = df_train[df_train[\"label\"]==1]\n",
    "df_since = df_train[df_train[\"label\"]==0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a pytorch dataset from the train samples and build a vocabulary using embedding vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_ince.to_csv(\"ince.csv\",index=False)\n",
    "# df_since.to_csv(\"since.csv\",index=False)\n",
    "\n",
    "# TEXT_IN = data.Field(tokenize='spacy', fix_length=100)\n",
    "# TEXT_SIN = data.Field(tokenize='spacy', fix_length=100)\n",
    "\n",
    "# ince_dataset = data.TabularDataset(\"ince.csv\", \"csv\", fields=[('text', TEXT_IN), ('label', LABEL)],skip_header=True)\n",
    "# since_dataset = data.TabularDataset(\"since.csv\", \"csv\", fields=[('text', TEXT_SIN), ('label', LABEL)],skip_header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load dataframe to csv\n",
    "# new_test.to_csv(\"test.csv\",index=False)\n",
    "df_train.to_csv(\"trainnew.csv\",index=False)\n",
    "df_test.to_csv(\"testnew.csv\",index=False)\n",
    "\n",
    "TEXT = data.Field(tokenize='spacy', fix_length=100)#preprocessing=generate_bigrams)\n",
    "LABEL = data.LabelField(dtype=torch.float)\n",
    "\n",
    "#processed data to Pytorch data set\n",
    "# test_dataset = data.TabularDataset(\"test.csv\", \"csv\", fields=[('text', TEXT), ('label', LABEL)],skip_header=True)\n",
    "train_dataset = data.TabularDataset(\"trainnew.csv\", \"csv\", fields=[('text', TEXT), ('label', LABEL)],skip_header=True)\n",
    "final_test_dataset = data.TabularDataset(\"testnew.csv\", \"csv\", fields=[('text', TEXT), ('label', LABEL)],skip_header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_vector(embeddings, word):\n",
    "#     assert word in embeddings.stoi, f'*{word}* is not in the vocab!'\n",
    "#     return embeddings.vectors[embeddings.stoi[word]]\n",
    "\n",
    "# def isin(embeddings, word):\n",
    "#     if word in embeddings.stoi:\n",
    "#         return True\n",
    "#     else:\n",
    "#         return False\n",
    "\n",
    "# def closest_words(embeddings, vector, n=10):\n",
    "#     distances = [(w, torch.dist(vector, get_vector(embeddings, w)).item()) for w in embeddings.itos]\n",
    "#     return sorted(distances, key = lambda w: w[1])[:n]\n",
    "\n",
    "# vars(train_dataset[0])[\"text\"]\n",
    "\n",
    "# reliable_vector = get_vector(vec, 'reliable')\n",
    "# reliable_misspellings = ['relieable', 'relyable', 'realible', 'realiable', 'relable', 'relaible', 'reliabe', 'relaiable']\n",
    "# diff_reliable = [(reliable_vector - get_vector(vec, s)).unsqueeze(0) for s in reliable_misspellings]\n",
    "\n",
    "# misspelling_vector = torch.cat(diff_reliable, dim=0).mean(dim=0)\n",
    "# closest_words(vec, get_vector(vec, 'becuase') + misspelling_vector)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# closest_words(vec, get_vector(vec, 'yuo') + misspelling_vector)[0][0]\n",
    "# #get_vector(vec,\"Eye\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchtext\n",
    "vec = torchtext.vocab.Vectors('glove.840B.300d/glove.840B.300d.txt', cache='./cache/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT.build_vocab(train_dataset, max_size=50000, vectors=vec)\n",
    "LABEL.build_vocab(train_dataset)\n",
    "\n",
    "# TEXT_IN.build_vocab(ince_dataset, max_size=50000, vectors=vec)\n",
    "# TEXT_SIN.build_vocab(since_dataset, max_size=50000, vectors=vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TEXT.vocab.vectors.shape\n",
    "# sincere = TEXT_SIN.vocab.freqs.most_common(500)\n",
    "# insincere = TEXT_IN.vocab.freqs.most_common(500)\n",
    "\n",
    "# sincere = [s for s,c in sincere]\n",
    "# insincere = [s for s,c in insincere]\n",
    "\n",
    "# common_in = []\n",
    "# common_sin = []\n",
    "# for s in insincere:\n",
    "#     if not(s in sincere):\n",
    "#         common_in.append(s)\n",
    "# for s in sincere:\n",
    "#     if not(s in insincere):\n",
    "#         common_sin.append(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from textblob import TextBlob\n",
    "\n",
    "# def isin(embeddings, word):\n",
    "#     if word in embeddings.stoi:\n",
    "#         return True\n",
    "#     else:\n",
    "#         return False\n",
    "\n",
    "\n",
    "# # b = TextBlob(\"hodl\")\n",
    "# # # print(b.correct())\n",
    "# # # print(vars(ince_dataset[0])[\"text\"])\n",
    "# # for t in ince_dataset:\n",
    "# #     text = vars(t)[\"text\"]\n",
    "# #     label = int(vars(t)[\"label\"])\n",
    "# #     for word in text:\n",
    "# #         if not isin(vec,word):\n",
    "# # #             w = TextBlob(word)\n",
    "# # #             c = w.correct()\n",
    "# #             if c in common_in:\n",
    "# #                 print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SPLIT DATA TO TRAINiNG AND VALIDATION SETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, test_dataset = train_dataset.split(random_state=random.seed(SEED))\n",
    "train_dataset, valid_dataset = train_dataset.split(random_state=random.seed(SEED))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 512\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "train_iterator = data.BucketIterator(\n",
    "    train_dataset, \n",
    "    batch_size=BATCH_SIZE,sort_key=lambda x: len(x.text), \n",
    "    device=device)\n",
    "test_iterator = data.BucketIterator(\n",
    "    test_dataset, \n",
    "    batch_size=BATCH_SIZE,sort_key=lambda x: len(x.text), \n",
    "    device=device)\n",
    "valid_iterator = data.BucketIterator(\n",
    "    valid_dataset, \n",
    "    batch_size=BATCH_SIZE,sort_key=lambda x: len(x.text), \n",
    "    device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50002, 300])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEXT.vocab.vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    \"\"\" Applies attention mechanism on the `context` using the `query`.\n",
    "    **Thank you** to IBM for their initial implementation of :class:`Attention`. Here is\n",
    "    their `License\n",
    "    <https://github.com/IBM/pytorch-seq2seq/blob/master/LICENSE>`__.\n",
    "    Args:\n",
    "        dimensions (int): Dimensionality of the query and context.\n",
    "        attention_type (str, optional): How to compute the attention score:\n",
    "            * dot: :math:`score(H_j,q) = H_j^T q`\n",
    "            * general: :math:`score(H_j, q) = H_j^T W_a q`\n",
    "    Example:\n",
    "         >>> attention = Attention(256)\n",
    "         >>> query = torch.randn(5, 1, 256)\n",
    "         >>> context = torch.randn(5, 5, 256)\n",
    "         >>> output, weights = attention(query, context)\n",
    "         >>> output.size()\n",
    "         torch.Size([5, 1, 256])\n",
    "         >>> weights.size()\n",
    "         torch.Size([5, 1, 5])\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dimensions, attention_type='general'):\n",
    "        super(Attention, self).__init__()\n",
    "\n",
    "        if attention_type not in ['dot', 'general']:\n",
    "            raise ValueError('Invalid attention type selected.')\n",
    "\n",
    "        self.attention_type = attention_type\n",
    "        if self.attention_type == 'general':\n",
    "            self.linear_in = nn.Linear(dimensions, dimensions, bias=False)\n",
    "\n",
    "        self.linear_out = nn.Linear(dimensions * 2, dimensions, bias=False)\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "    def forward(self, query, context):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            query (:class:`torch.FloatTensor` [batch size, output length, dimensions]): Sequence of\n",
    "                queries to query the context.\n",
    "            context (:class:`torch.FloatTensor` [batch size, query length, dimensions]): Data\n",
    "                overwhich to apply the attention mechanism.\n",
    "        Returns:\n",
    "            :class:`tuple` with `output` and `weights`:\n",
    "            * **output** (:class:`torch.LongTensor` [batch size, output length, dimensions]):\n",
    "              Tensor containing the attended features.\n",
    "            * **weights** (:class:`torch.FloatTensor` [batch size, output length, query length]):\n",
    "              Tensor containing attention weights.\n",
    "        \"\"\"\n",
    "        batch_size, output_len, dimensions = query.size()\n",
    "        query_len = context.size(1)\n",
    "\n",
    "        if self.attention_type == \"general\":\n",
    "            query = query.view(batch_size * output_len, dimensions)\n",
    "            query = self.linear_in(query)\n",
    "            query = query.view(batch_size, output_len, dimensions)\n",
    "\n",
    "        # TODO: Include mask on PADDING_INDEX?\n",
    "\n",
    "        # (batch_size, output_len, dimensions) * (batch_size, query_len, dimensions) ->\n",
    "        # (batch_size, output_len, query_len)\n",
    "        attention_scores = torch.bmm(query, context.transpose(1, 2).contiguous())\n",
    "\n",
    "        # Compute weights across every context sequence\n",
    "        attention_scores = attention_scores.view(batch_size * output_len, query_len)\n",
    "        attention_weights = self.softmax(attention_scores)\n",
    "        attention_weights = attention_weights.view(batch_size, output_len, query_len)\n",
    "\n",
    "        # (batch_size, output_len, query_len) * (batch_size, query_len, dimensions) ->\n",
    "        # (batch_size, output_len, dimensions)\n",
    "        mix = torch.bmm(attention_weights, context)\n",
    "\n",
    "        # concat -> (batch_size * output_len, 2*dimensions)\n",
    "        combined = torch.cat((mix, query), dim=2)\n",
    "        combined = combined.view(batch_size * output_len, 2 * dimensions)\n",
    "\n",
    "        # Apply linear_out on every 2nd dimension of concat\n",
    "        # output -> (batch_size, output_len, dimensions)\n",
    "        output = self.linear_out(combined).view(batch_size, output_len, dimensions)\n",
    "        output = self.tanh(output)\n",
    "\n",
    "        return output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, n_filters, filter_sizes, output_dim, dropout):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.convs = nn.ModuleList([nn.Conv2d(in_channels=1, out_channels=n_filters, kernel_size=(fs,embedding_dim)) for fs in filter_sizes])\n",
    "        self.fc = nn.Linear(len(filter_sizes)*n_filters, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        #x = [sent len, batch size]\n",
    "        x = x.permute(1, 0)\n",
    "        #x = [batch size, sent len]\n",
    "        embedded = self.embedding(x)\n",
    "        #embedded = [batch size, sent len, emb dim]\n",
    "        embedded = embedded.unsqueeze(1)\n",
    "        #embedded = [batch size, 1, sent len, emb dim]\n",
    "        conved = [F.relu(conv(embedded)).squeeze(3) for conv in self.convs]\n",
    "        #conv_n = [batch size, n_filters, sent len - filter_sizes[n]]\n",
    "        pooled = [F.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in conved]\n",
    "        #pooled_n = [batch size, n_filters]\n",
    "        cat = self.dropout(torch.cat(pooled, dim=1))\n",
    "        #cat = [batch size, n_filters * len(filter_sizes)]\n",
    "            \n",
    "        return self.fc(cat)\n",
    "    \n",
    "class BiLSTM(nn.Module):\n",
    "    def __init__(self, pretrained_lm, padding_idx, static=True, hidden_dim=128, lstm_layer=2, dropout=0.2):\n",
    "        super(BiLSTM, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.embedding = nn.Embedding.from_pretrained(pretrained_lm)\n",
    "        self.embedding.padding_idx = padding_idx\n",
    "        if static:\n",
    "            self.embedding.weight.requires_grad = False\n",
    "        self.lstm = nn.LSTM(input_size=self.embedding.embedding_dim,\n",
    "                            hidden_size=hidden_dim,\n",
    "                            num_layers=lstm_layer, \n",
    "                            dropout = dropout,\n",
    "                            bidirectional=True)\n",
    "        self.hidden2label = nn.Linear(hidden_dim*lstm_layer*2, 1)\n",
    "    \n",
    "    def forward(self, sents):\n",
    "        x = self.embedding(sents)\n",
    "        x = torch.transpose(x, dim0=1, dim1=0)\n",
    "        lstm_out, (h_n, c_n) = self.lstm(x)\n",
    "        y = self.hidden2label(self.dropout(torch.cat([c_n[i,:, :] for i in range(c_n.shape[0])], dim=1)))\n",
    "        return y    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = len(TEXT.vocab)\n",
    "EMBEDDING_DIM = 300\n",
    "N_FILTERS = 100\n",
    "FILTER_SIZES = [3,4,5]\n",
    "OUTPUT_DIM = 1\n",
    "DROPOUT = 0.5\n",
    "\n",
    "# model = CNN(INPUT_DIM, EMBEDDING_DIM, N_FILTERS, FILTER_SIZES, OUTPUT_DIM, DROPOUT)\n",
    "model = BiLSTM(TEXT.vocab.vectors, lstm_layer=2, padding_idx=TEXT.vocab.stoi[TEXT.pad_token], hidden_dim=128).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [-0.0869,  0.1916,  0.1091,  ..., -0.0152,  0.1111,  0.2065],\n",
       "        ...,\n",
       "        [-0.7941, -0.6765,  0.3061,  ...,  0.0766,  0.4567,  0.1807],\n",
       "        [ 0.0925, -0.3773, -0.1634,  ..., -0.3725,  0.1818, -0.4889],\n",
       "        [-0.2422, -0.4782, -0.0560,  ...,  0.1407,  0.4678,  0.0412]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_embeddings = TEXT.vocab.vectors\n",
    "\n",
    "model.embedding.weight.data.copy_(pretrained_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# optimizer = optim.Adam(model.parameters())\n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()),\n",
    "                    lr=1e-3)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)\n",
    "\n",
    "def binary_accuracy(preds, y, th = 0.5):\n",
    "    \"\"\"\n",
    "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
    "    \"\"\"\n",
    "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
    "    correct = (rounded_preds == y).float() #convert into float for division \n",
    "    acc = correct.sum()/len(correct)\n",
    "    return acc\n",
    "\n",
    "def f1_score_model(preds, y,th = 0.5):\n",
    "    \"\"\"\n",
    "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
    "    \"\"\"\n",
    "    rounded = torch.sigmoid(preds).cpu().apply_(lambda x: 1 if x>=th else 0)\n",
    "    rounded_preds = rounded\n",
    "\n",
    "    return sklearn.metrics.f1_score(y.cpu().numpy(),rounded_preds.cpu().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for batch in iterator:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        predictions = model(batch.text).squeeze(1)\n",
    "        loss = criterion(predictions, batch.label)\n",
    "        \n",
    "        acc = binary_accuracy(predictions, batch.label)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
    "\n",
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for batch in iterator:\n",
    "\n",
    "            predictions = model(batch.text).squeeze(1)\n",
    "            \n",
    "            loss = criterion(predictions, batch.label)\n",
    "\n",
    "            acc = binary_accuracy(predictions, batch.label)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
    "\n",
    "def evaluateFinal(model, iterator):\n",
    "       \n",
    "    model.eval()\n",
    "    all_predictions = []\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for batch in iterator:\n",
    "\n",
    "            predictions = model(batch.text).squeeze(1)\n",
    "            all_predictions = all_predictions + list(predictions)\n",
    "    return all_predictions\n",
    "\n",
    "def evaluate_f1(model, iterator, criterion,th=0.5):\n",
    "    \n",
    "    f1_scores = []\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for batch in iterator:\n",
    "\n",
    "            predictions = model(batch.text).squeeze(1)\n",
    "            \n",
    "            f1 = f1_score_model(predictions, batch.label,th=th)\n",
    "            f1_scores.append(f1)\n",
    "        \n",
    "    return np.array(f1_scores).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Target size (torch.Size([512])) must be the same as input size (torch.Size([100]))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-17fe78a088e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN_EPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mvalid_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-34-2408479afd44>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, iterator, optimizer, criterion)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbinary_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/spiros/diskoyext/anaconda18103/envs/deep-learning/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/spiros/diskoyext/anaconda18103/envs/deep-learning/lib/python3.7/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    593\u001b[0m                                                   \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    594\u001b[0m                                                   \u001b[0mpos_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 595\u001b[0;31m                                                   reduction=self.reduction)\n\u001b[0m\u001b[1;32m    596\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/spiros/diskoyext/anaconda18103/envs/deep-learning/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbinary_cross_entropy_with_logits\u001b[0;34m(input, target, weight, size_average, reduce, reduction, pos_weight)\u001b[0m\n\u001b[1;32m   2073\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2074\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2075\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Target size ({}) must be the same as input size ({})\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2076\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2077\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy_with_logits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction_enum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Target size (torch.Size([512])) must be the same as input size (torch.Size([100]))"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 5\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
    "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
    "    \n",
    "    print(f'| Epoch: {epoch+1:02} | Train Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}% | Val. Loss: {valid_loss:.3f} | Val. Acc: {valid_acc*100:.2f}% |')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = evaluate(model, test_iterator, criterion)\n",
    "\n",
    "print(f'| Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}% |')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = evaluate_f1(model, test_iterator, criterion,th = 0.31)\n",
    "print(f'| f1 score: {score:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PREDICTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_test_iterator = data.BucketIterator(\n",
    "#     final_test_dataset, \n",
    "#     batch_size=1024,sort_key=lambda x: len(x.text), \n",
    "#     device=device)\n",
    "\n",
    "\n",
    "# m = evaluateFinal(model,final_test_iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_t = pd.read_csv(\"test.csv\")\n",
    "# out_df = pd.DataFrame({\"qid\":df_t[\"qid\"].values})\n",
    "# out_df[\"prediction\"] = m\n",
    "# out_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# out_df[\"prediction\"] = out_df[\"prediction\"].apply(lambda x: int((torch.round(torch.sigmoid(x))).item()))\n",
    "# out_df.to_csv(\"submission.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# out_df.head()\n",
    "# TEXT.tokenize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_t = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The prediction function\n",
    "\n",
    "The function accepts a minimum length argument. If the tokenized input text is less than the minimum length \n",
    "we append the tokens with `<pad>` to make it the minimum length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en')\n",
    "\n",
    "def predict(sentence, min_len=5):\n",
    "    tokenized = [tok.text for tok in nlp.tokenizer(sentence)]\n",
    "    tokenized = tokenized[:100]\n",
    "    if len(tokenized) < min_len:\n",
    "        tokenized += ['<pad>'] * (min_len - len(tokenized))\n",
    "    indexed = [TEXT.vocab.stoi[t] for t in tokenized]\n",
    "    tensor = torch.LongTensor(indexed).to(device)\n",
    "    tensor = tensor.unsqueeze(1)\n",
    "    prediction =0\n",
    "    if torch.sigmoid(model(tensor)) >= 0.31:\n",
    "        prediction = 1\n",
    "    else:\n",
    "        prediction = 0\n",
    "#     prediction = torch.round(torch.sigmoid(model(tensor)))\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_meta = np.zeros(test_X.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_df = pd.DataFrame({\"qid\":df_t[\"qid\"].values})\n",
    "out_df[\"prediction\"] = df_t[\"question_text\"].apply(lambda x: predict(x))\n",
    "out_df[\"prediction\"] = out_df[\"prediction\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_df.to_csv(\"submission.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(len(out_df[out_df[\"prediction\"]==1])/len(out_df))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
